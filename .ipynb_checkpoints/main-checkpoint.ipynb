{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **install textblob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /home/rudda/.local/lib/python3.6/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/rudda/.local/lib/python3.6/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: regex in /home/rudda/.local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (2020.10.28)\n",
      "Requirement already satisfied: joblib in /home/rudda/.local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
      "Requirement already satisfied: click in /home/rudda/.local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/rudda/.local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (4.51.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: googletrans in /home/rudda/.local/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: requests in /home/rudda/.local/lib/python3.6/site-packages (from googletrans) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/rudda/.local/lib/python3.6/site-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/rudda/.local/lib/python3.6/site-packages (from requests->googletrans) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/rudda/.local/lib/python3.6/site-packages (from requests->googletrans) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rudda/.local/lib/python3.6/site-packages (from requests->googletrans) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install textblob\n",
    "!pip3 install googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "import json \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tranlate file and salve in other file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data translate finish!!\n"
     ]
    }
   ],
   "source": [
    "#valid v6 and v7\n",
    "dataset = open('data/dataset-v2.dat', 'r', encoding='utf-8')\n",
    "data_rudda = open('data/data-split/dataset-full-2.json', 'a', encoding='utf-8')\n",
    "data_wagner = open('data/data-split/dataset-50k-75k-wagner.json', 'a', encoding='utf-8')\n",
    "data_rafael = open('data/data-split/dataset-75k-100k-rafael.json', 'a', encoding='utf-8')\n",
    "\n",
    "#dataset = open('data/dataset-us-v6.json', 'r', encoding='utf-8')\n",
    "#data_us = open('data/dataset-us-v7.json', 'a', encoding='utf-8')\n",
    "data_ex = open('data/data-split/dataset-us-except-v1.json', 'a', encoding='utf-8')\n",
    "i =0;\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "latest_review_id = \"277107720\"\n",
    "translate = False\n",
    "aux_json = \"\"\n",
    "\n",
    "to_translate = {\n",
    "    'title' :'',\n",
    "    'reviewBody' :'',\n",
    "    'reviewId' : ''\n",
    "}\n",
    "\n",
    "for line in dataset:\n",
    "       \n",
    "    try:\n",
    "        translator = Translator()\n",
    "        i  = i + 1;\n",
    "        # parse to json format\n",
    "        data_json = json.loads(str(line))\n",
    "        #print(str(data_json['reviewBody']))\n",
    "        #aux_json = data_json\n",
    "        # remove emojis\n",
    "        #review_str = emoji_pattern.sub(r'', str(data_json['reviewBody'])) \n",
    "        #title\n",
    "        #title_str = emoji_pattern.sub(r'', str(data_json['title'])) \n",
    "       # if( translate == True ):\n",
    "        #print('Im translating',review_str, title_str)\n",
    "            #translate\n",
    "        #review_str = translator.translate( review_str, dest='en') \n",
    "       # title_str = translator.translate( str(title_str), dest='en')\n",
    "            #assigne\n",
    "        #to_translate['reviewBody'] = review_str\n",
    "       # to_translate['title'] = title_str\n",
    "       # to_translate['reviewId'] = data_json['reviewId']\n",
    "        #write file\n",
    "        #data_us.write(json.dumps(data_json) + \"\\n\")\n",
    "            # logs\n",
    "        #if(i <= 50000):\n",
    "        data_rudda.write(json.dumps(data_json) + \",\\n\")\n",
    "        #if( i > 50000 and i <= 75000):\n",
    "       #     data_wagner.write(json.dumps(to_translate) + \"\\n\")\n",
    "        #if( i> 75000):\n",
    "        #    data_rafael.write(json.dumps(to_translate) + \"\\n\")\n",
    "            \n",
    "        \n",
    "        #if( data_json['reviewId'] == latest_review_id and not bool(translate)):\n",
    "           # translate = True;\n",
    "           # print('hey there!!')\n",
    "        \n",
    "       # if(not bool(translate) ):\n",
    "           # print('locking for ..', latest_review_id, data_json['reviewId'])\n",
    "            \n",
    "    except:\n",
    "     #   print('except')\n",
    "        print(str(line) + '\\n')\n",
    "      #  data_ex.write(json.dumps(aux_json) + \"\\n\")\n",
    "       \n",
    "    \n",
    "#data_us.close()\n",
    "data_rudda.close()\n",
    "#data_wagner.close()\n",
    "#data_rafael.close()\n",
    "dataset.close()\n",
    "print('data translate finish!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
